# LLM_Unlearning_Papers


## Category
### Parameter optimization 	
1. **KGA: A General Machine Unlearning Framework Based on Knowledge Gap Alignment.** (ACL 2023) <br />
 Lingzhi Wang, Tong Chen, Wei Yuan, Xingshan Zeng, Kam-Fai Wong, and Hongzhi Yin.
 [[paper](https://arxiv.org/abs/2305.06535)] [[code](https://github.com/Lingzhi-WANG/KGAUnlearn)]

2. **Knowledge unlearning for mitigating privacy risks in language models.** (ACL 2023) <br />
 Joel Jang, Dongkeun Yoon, Sohee Yang, Sungmin Cha, Moontae Lee, Lajanugen Logeswaran, and Minjoon Seo.
 [[paper](https://arxiv.org/abs/2210.01504)] [[code](https://github.com/joeljang/knowledge-unlearning)]

3. **Unlearn What You Want to Forget: Efficient Unlearning for LLMs.**  <br />
 Jiaao Chen, Diyi Yang.
 [[paper](https://arxiv.org/abs/2310.20150)] [[code](https://github.com/SALT-NLP/Efficient_Unlearning)]

4. **Large Language Model Unlearning.**  <br />
 Yuanshun Yao, Xiaojun Xu, and Yang Liu.
 [[paper](https://arxiv.org/abs/2310.10683)] [[code](https://github.com/kevinyaobytedance/llm_unlearn)]

5. **DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models.**  <br />
 Xinwei Wu, Junzhuo Li, Minghui Xu, Weilong Dong, Shuangzhi Wu, Chao Bian, and Deyi Xiong.
 [[paper](https://arxiv.org/abs/2310.20138)] [[code](https://github.com/flamewei123/DEPN)]

6. **Who's Harry Potter? Approximate Unlearning in LLMs.**  <br />
 Ronen Eldan, Mark Russinovich.
 [[paper](https://arxiv.org/abs/2310.02238)]

7. **Unlearning Bias in Language Models by Partitioning Gradients.** (ACL 2023) <br />
 Charles Yu, Sullam Jeoung, Anish Kasi, Pengfei Yu, Heng Ji.
 [[paper](https://aclanthology.org/2023.findings-acl.375/)] [[code](https://github.com/CharlesYu2000/PCGU-UnlearningBias)]

9. **Make Text Unlearnable: Exploiting Effective Patterns to Protect Personal Data.**  <br />
 Xinzhe Li, Ming Liu, Shang Gao.
 [[paper](https://arxiv.org/abs/2307.00456)]

10. **Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation.**  <br />
 Xinshuo Hu, Dongfang Li, Zihao Zheng, Zhenyu Liu, Baotian Hu, Min Zhang.
 [[paper](https://arxiv.org/abs/2308.08090)] 

11. **Making Harmful Behaviors Unlearnable for Large Language Models.**  <br />
 Xin Zhou, Yi Lu, Ruotian Ma, Tao Gui, Qi Zhang, Xuanjing Huang.
 [[paper](https://arxiv.org/abs/2311.02105)] 

### Parameter merging
1. **Editing Models with Task Arithmetic.**  <br />
 Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi.
 [[paper](https://arxiv.org/abs/2212.04089)] [[code](https://github.com/mlfoundations/task_vectors)]

2. **Composing Parameter-Efficient Modules with Arithmetic Operations.**  <br />
 Jinghan Zhang, Shiqi Chen, Junteng Liu, and Junxian He.
 [[paper](https://arxiv.org/abs/2306.14870)] [[code](https://github.com/SJTU-LIT/PEM_composition)]

3. **Fuse to Forget: Bias Reduction and Selective Memorization through Model Fusion.**  <br />
 Kerem Zaman, Leshem Choshen, Shashank Srivastava.
 [[paper](https://arxiv.org/abs/2311.07682)] [[code](https://github.com/KeremZaman/FuseToForget)]

### In-context learning
1. **in-context unlearning: language models as few shot unlearners.**  <br />
 Martin Pawelczyk, Seth Neel, and Himabindu Lakkaraju.
 [[paper](https://arxiv.org/abs/2310.07579)]
